# ğŸ§  ChurnInsight â€“ Data Science

Este directorio contiene el **componente de Data Science** del proyecto **ChurnInsight**, encargado del anÃ¡lisis de datos, construcciÃ³n, evaluaciÃ³n y preparaciÃ³n del modelo de *Machine Learning* para la **predicciÃ³n de churn (cancelaciÃ³n de clientes)**.
Con este mÃ³dulo se busca generar un modelo confiable, interpretable y listo para producciÃ³n, que serÃ¡ consumido por la **API REST desarrollada en Spring Boot**.

---

## ğŸ¯ Objetivo de Negocio

El objetivo del modelo de churn es **anticipar la cancelaciÃ³n de clientes** para permitir a la empresa:

- Implementar estrategias de retenciÃ³n temprana
- Reducir pÃ©rdidas de ingresos por cancelaciones no anticipadas
- Priorizar acciones comerciales sobre clientes de alto riesgo
- Optimizar campaÃ±as de fidelizaciÃ³n basadas en datos

Desde una perspectiva de negocio, el costo de **no detectar un churner (False Negative)** es significativamente mayor que el de contactar a un cliente que no iba a cancelar, razÃ³n por la cual se priorizan mÃ©tricas como *Recall* y *F2-score*.

---

## ğŸ“Œ Alcance del componente de Data Science

- AnÃ¡lisis Exploratorio de Datos (EDA)
- Pipeline ETL (limpieza, transformaciÃ³n y validaciÃ³n)
- Feature engineering
- Entrenamiento y evaluaciÃ³n de modelos supervisados
- SelecciÃ³n del mejor modelo
- SerializaciÃ³n del modelo para despliegue
- Base para el microservicio de inferencia en Python

---

## ğŸ“ Estructura del directorio

data-science/
- â”œâ”€â”€ data/
- â”‚   â”œâ”€â”€ data_original.csv        # Dataset original (sin modificaciones)
- â”‚   â””â”€â”€ data_limpia.csv          # Dataset limpio y transformado (post-ETL)
- â”‚
- â”œâ”€â”€ notebooks/
- â”‚   â””â”€â”€ ChurnInsight_ETL-ML.ipynb # ETL + EDA + Entrenamiento y evaluaciÃ³n de modelos
- â”‚
- â”œâ”€â”€ models/
- â”‚   â”œâ”€â”€ logreg_baseline.joblib   # RegresiÃ³n LogÃ­stica (baseline)
- â”‚   â”œâ”€â”€ logreg_optimized.joblib  # RegresiÃ³n LogÃ­stica optimizada (modelo final)
- â”‚   â”œâ”€â”€ tree_baseline.joblib     # Ãrbol de DecisiÃ³n (baseline)
- â”‚   â”œâ”€â”€ tree_optimized.joblib    # Ãrbol de DecisiÃ³n optimizado
- â”‚   â”œâ”€â”€ rf_baseline.joblib       # Random Forest (baseline)
- â”‚   â””â”€â”€ rf_optimized.joblib      # Random Forest optimizado
- â”‚
- â””â”€â”€ README.md                    # DocumentaciÃ³n del componente de Data Science


## ğŸ“Š Dataset

- **Nombre:** Netflix Customer Churn  
- **Fuente:** Kaggle  
- **DescripciÃ³n:**  
  Dataset con informaciÃ³n demogrÃ¡fica, de uso y comportamiento de clientes, incluyendo la variable objetivo `churned`.

### Variable objetivo
- `churned`:
  - `True` â†’ Cliente cancelÃ³ el servicio  
  - `False` â†’ Cliente permaneciÃ³  

---

## ğŸ” Pipeline ETL

El pipeline de datos incluye:

1. **ExtracciÃ³n**
   - Carga del dataset desde GitHub (RAW) para garantizar reproducibilidad.

2. **TransformaciÃ³n**
   - Limpieza de datos
   - ConversiÃ³n de tipos
   - EstandarizaciÃ³n de variables categÃ³ricas
   - CreaciÃ³n de identificador pÃºblico anonimizado (`public_id`)
   - CodificaciÃ³n de variables categÃ³ricas

3. **ValidaciÃ³n**
   - VerificaciÃ³n de valores nulos
   - Control de duplicados
   - RevisiÃ³n de consistencia semÃ¡ntica

---

## ğŸ“ˆ AnÃ¡lisis Exploratorio de Datos (EDA)

Durante el EDA se realizaron:

- EstadÃ­sticas descriptivas de variables numÃ©ricas
- AnÃ¡lisis de distribuciÃ³n de la variable churn
- AnÃ¡lisis porcentual de variables categÃ³ricas
- Visualizaciones:
  - GrÃ¡ficos de barras
  - GrÃ¡ficos circulares
  - Boxplots churn vs variables numÃ©ricas

### Hallazgos clave
- El churn presenta una distribuciÃ³n relativamente equilibrada.
- El **engagement del cliente** (horas de visualizaciÃ³n) es un factor determinante.
- Variables de uso muestran mayor poder explicativo que las demogrÃ¡ficas.

---

## ğŸ¤– Modelado de Machine Learning

## ğŸ” Control de Data Leakage

Durante el desarrollo se identificaron y eliminaron variables con riesgo de *data leakage*, tales como:

- Variables derivadas directamente del target
- InformaciÃ³n posterior al evento de churn
- Identificadores sin valor predictivo

Este control permitiÃ³:
- Evitar mÃ©tricas artificialmente infladas
- Garantizar generalizaciÃ³n del modelo
- Asegurar un comportamiento realista en producciÃ³n

Las mÃ©tricas finales reflejan un escenario **mÃ¡s cercano al mundo real**.


### Modelos entrenados
- RegresiÃ³n LogÃ­stica
- Ãrbol de DecisiÃ³n
- Random Forest

### MÃ©tricas utilizadas
- Accuracy
- Precision
- Recall
- F1-score

### Mejor modelo (estado actual)
**RegresiÃ³n logÃ­stica**

- Accuracy â‰ˆ 0.769  
- Precision â‰ˆ 0.7297  
- Recall â‰ˆ 0.8588  
- F1-score â‰ˆ 0.7890
- F2-score â‰ˆ 0.8295

El modelo que presentÃ³ el mejor equilibrio entre detecciÃ³n de churn y control de errores fue la RegresiÃ³n LogÃ­stica (LogReg), destacÃ¡ndose especialmente en la mÃ©trica F2-score, que da mayor peso al recall, clave para minimizar clientes que cancelan sin ser detectados.

## ğŸ“ Criterio de EvaluaciÃ³n

Dado el contexto del problema, se priorizÃ³ la mÃ©trica **F2-score**, que otorga mayor peso al *Recall* que a la *Precision*.

### JustificaciÃ³n:
- **False Negatives (churn no detectado)** â†’ pÃ©rdida directa de cliente
- **False Positives** â†’ costo operativo asumible (contacto preventivo)

Por este motivo, el modelo seleccionado maximiza la detecciÃ³n de clientes en riesgo, incluso a costa de aumentar ligeramente los falsos positivos.

## âš ï¸ Limitaciones

- Dataset sintÃ©tico con tasa de churn ~50%, superior a escenarios reales
- No se incluyeron variables temporales o de secuencia
- El modelo no incorpora costos econÃ³micos explÃ­citos
- No se implementÃ³ aÃºn recalibraciÃ³n periÃ³dica del modelo

Estas limitaciones se consideran en el roadmap de evoluciÃ³n del proyecto.

---

## ğŸ’¾ Persistencia del modelo

- Los modelos entrenados se serializan usando `joblib`.
- El modelo final estÃ¡ preparado para:
  - Despliegue como microservicio Python
  - Consumo desde la API REST (Spring Boot)
  - Versionamiento y actualizaciÃ³n futura

---

## ğŸ”Œ IntegraciÃ³n con la API

Este componente se integrarÃ¡ con la API **ChurnInsight** mediante:

- Un microservicio Python de inferencia
- ComunicaciÃ³n vÃ­a HTTP (JSON)
- Entrada alineada con los DTOs definidos en la API

---

## ğŸš§ Estado actual

- âœ” ETL completo  
- âœ” EDA documentado  
- âœ” Modelos entrenados y evaluados  
- âœ” Modelo final seleccionado  
- âœ” Modelo serializado  
- âœ” Microservicio Python (en desarrollo)  

---

## ğŸš€ PrÃ³ximos Pasos

- Incorporar modelos avanzados:
  - Gradient Boosting (XGBoost, LightGBM)
- Implementar explicabilidad avanzada:
  - SHAP / LIME
- Ajuste dinÃ¡mico del umbral de decisiÃ³n
- Monitoreo de drift de datos y mÃ©tricas
- AutomatizaciÃ³n del pipeline de entrenamiento
- IntegraciÃ³n con dashboards de negocio

Este roadmap permitirÃ¡ evolucionar el sistema hacia un entorno MLOps completo.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

- Python 3.10+
- Pandas
- NumPy
- Matplotlib / Seaborn
- Scikit-learn
- Joblib

---

## ğŸ‘¥ Equipo â€“ Data Science

- [Rocio Isabel Davila Elias](https://www.linkedin.com/in/rociodavila15/)
- [Elizabeth Garces Isaza](https://www.linkedin.com/in/ing-elizabeth-garces-isaza/)
- [Leslie Rodriguez NuÃ±ez](https://www.linkedin.com/in/leslie-rodriguez-a2679726a/)

---

## ğŸ ConclusiÃ³n

El componente de Data Science de **ChurnInsight** proporciona una soluciÃ³n robusta, explicable y alineada con objetivos de negocio para la predicciÃ³n de churn.  
El modelo seleccionado equilibra desempeÃ±o, interpretabilidad y viabilidad productiva, sentando una base sÃ³lida para su escalado e integraciÃ³n en entornos reales.

